{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b924ebe1",
   "metadata": {},
   "source": [
    "# Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d2e0d0",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c630a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "import pyspark\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrameReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de88a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation de findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660e1c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du SparkSession\n",
    "spark = SparkSession.builder.appName(\"Exemple Spark\").getOrCreate()\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a9cb1f",
   "metadata": {},
   "source": [
    "## Create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a029abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstDict = [{'prenom': 'Kareem','nom': 'Abdul-jabbar', 'points': 1560},\n",
    "           {'prenom': 'Karl','nom': 'Malone','points': 1476},\n",
    "           {'prenom': 'Michael','nom': 'Jordan','points': 1072},\n",
    "           {'prenom': 'Wilt','nom': 'Chamberlain','points': 1045},\n",
    "           {'prenom': 'Oneil','nom': 'Shaquille','points': 1147}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "472cdbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(lstDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "307d8d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+-------+\n",
      "|         nom|points| prenom|\n",
      "+------------+------+-------+\n",
      "|Abdul-jabbar|  1560| Kareem|\n",
      "|      Malone|  1476|   Karl|\n",
      "|      Jordan|  1072|Michael|\n",
      "| Chamberlain|  1045|   Wilt|\n",
      "|   Shaquille|  1147|  Oneil|\n",
      "+------------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.createDataFrame(rdd)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef802d7",
   "metadata": {},
   "source": [
    "## Rajouter une colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef3c36f",
   "metadata": {},
   "source": [
    "Créer une fonction udf pour ajouter une colonne lensup10 avec true si le nom de la personne dépasse 10 caractères sinon false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5668b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_len_sup_10 = F.udf(lambda x : len(x) >= 10, BooleanType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc58e992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+-------+----------+\n",
      "|         nom|points| prenom|len_sup_10|\n",
      "+------------+------+-------+----------+\n",
      "|Abdul-jabbar|  1560| Kareem|      true|\n",
      "|      Malone|  1476|   Karl|     false|\n",
      "|      Jordan|  1072|Michael|     false|\n",
      "| Chamberlain|  1045|   Wilt|      true|\n",
      "|   Shaquille|  1147|  Oneil|     false|\n",
      "+------------+------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('len_sup_10', udf_len_sup_10(df.nom)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ac68f",
   "metadata": {},
   "source": [
    "# Exercice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fdc1c",
   "metadata": {},
   "source": [
    "## Méthode 1 pour lire un dataframe depuis un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba561c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+-------+\n",
      "|userID|    name|age|friends|\n",
      "+------+--------+---+-------+\n",
      "|     0|    Will| 33|    385|\n",
      "|     1|Jean-Luc| 26|      2|\n",
      "|     2|    Hugh| 55|    221|\n",
      "|     3|  Deanna| 40|    465|\n",
      "|     4|   Quark| 68|     21|\n",
      "|     5|  Weyoun| 59|    318|\n",
      "|     6|  Gowron| 37|    220|\n",
      "|     7|    Will| 54|    307|\n",
      "|     8|  Jadzia| 38|    380|\n",
      "|     9|    Hugh| 27|    181|\n",
      "|    10|     Odo| 53|    191|\n",
      "|    11|     Ben| 57|    372|\n",
      "|    12|   Keiko| 54|    253|\n",
      "|    13|Jean-Luc| 56|    444|\n",
      "|    14|    Hugh| 43|     49|\n",
      "|    15|     Rom| 36|     49|\n",
      "|    16|  Weyoun| 22|    323|\n",
      "|    17|     Odo| 35|     13|\n",
      "|    18|Jean-Luc| 45|    455|\n",
      "|    19|  Geordi| 60|    246|\n",
      "+------+--------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\",\"true\").load(\"./Exercices_Dataframe/fakefriends_header.csv\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f121f",
   "metadata": {},
   "source": [
    "## Méthode 2 pour lire un dataframe depuis un csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6874e38",
   "metadata": {},
   "source": [
    "Méthode la plus pratique, a utiliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070dd85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+-------+\n",
      "|userID|    name|age|friends|\n",
      "+------+--------+---+-------+\n",
      "|     0|    Will| 33|    385|\n",
      "|     1|Jean-Luc| 26|      2|\n",
      "|     2|    Hugh| 55|    221|\n",
      "|     3|  Deanna| 40|    465|\n",
      "|     4|   Quark| 68|     21|\n",
      "|     5|  Weyoun| 59|    318|\n",
      "|     6|  Gowron| 37|    220|\n",
      "|     7|    Will| 54|    307|\n",
      "|     8|  Jadzia| 38|    380|\n",
      "|     9|    Hugh| 27|    181|\n",
      "|    10|     Odo| 53|    191|\n",
      "|    11|     Ben| 57|    372|\n",
      "|    12|   Keiko| 54|    253|\n",
      "|    13|Jean-Luc| 56|    444|\n",
      "|    14|    Hugh| 43|     49|\n",
      "|    15|     Rom| 36|     49|\n",
      "|    16|  Weyoun| 22|    323|\n",
      "|    17|     Odo| 35|     13|\n",
      "|    18|Jean-Luc| 45|    455|\n",
      "|    19|  Geordi| 60|    246|\n",
      "+------+--------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read.format(\"csv\").option(\"header\",\"true\").load(\"./Exercices_Dataframe/fakefriends_header.csv\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a600a",
   "metadata": {},
   "source": [
    "## Déterminer le nombre moyen d’amis ventilé par âge des personnes dans ce réseau social."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6a177e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userID: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- friends: integer (nullable = true)\n",
      "\n",
      "+------+--------+---+-------+\n",
      "|userID|    name|age|friends|\n",
      "+------+--------+---+-------+\n",
      "|     0|    Will| 33|    385|\n",
      "|     1|Jean-Luc| 26|      2|\n",
      "|     2|    Hugh| 55|    221|\n",
      "|     3|  Deanna| 40|    465|\n",
      "|     4|   Quark| 68|     21|\n",
      "|     5|  Weyoun| 59|    318|\n",
      "|     6|  Gowron| 37|    220|\n",
      "|     7|    Will| 54|    307|\n",
      "|     8|  Jadzia| 38|    380|\n",
      "|     9|    Hugh| 27|    181|\n",
      "|    10|     Odo| 53|    191|\n",
      "|    11|     Ben| 57|    372|\n",
      "|    12|   Keiko| 54|    253|\n",
      "|    13|Jean-Luc| 56|    444|\n",
      "|    14|    Hugh| 43|     49|\n",
      "|    15|     Rom| 36|     49|\n",
      "|    16|  Weyoun| 22|    323|\n",
      "|    17|     Odo| 35|     13|\n",
      "|    18|Jean-Luc| 45|    455|\n",
      "|    19|  Geordi| 60|    246|\n",
      "+------+--------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.selectExpr(\"cast(userID as int) userID\",\n",
    "    \"cast(name as string) name\",\n",
    "    \"cast(age as int) age\",\n",
    "    \"cast(friends as int) friends\")\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d626e228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|age|      avg(friends)|\n",
      "+---+------------------+\n",
      "| 18|           343.375|\n",
      "| 19|213.27272727272728|\n",
      "| 20|             165.0|\n",
      "| 21|           350.875|\n",
      "| 22|206.42857142857142|\n",
      "| 23|             246.3|\n",
      "| 24|             233.8|\n",
      "| 25|197.45454545454547|\n",
      "| 26|242.05882352941177|\n",
      "| 27|           228.125|\n",
      "| 28|             209.1|\n",
      "| 29|215.91666666666666|\n",
      "| 30| 235.8181818181818|\n",
      "| 31|            267.25|\n",
      "| 32| 207.9090909090909|\n",
      "| 33| 325.3333333333333|\n",
      "| 34|             245.5|\n",
      "| 35|           211.625|\n",
      "| 36|             246.6|\n",
      "| 37|249.33333333333334|\n",
      "+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy(\"age\").mean(\"friends\").orderBy(\"age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907eefe3",
   "metadata": {},
   "source": [
    "# Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "976994c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\\\n",
    "    StructField(\"station\", StringType(), True),\\\n",
    "    StructField(\"id\", IntegerType(), True),\\\n",
    "    StructField(\"Temp\", StringType(), True),\\\n",
    "    StructField(\"Value\", IntegerType(), True),\\\n",
    "    StructField(\"col4\", StringType(), True),\\\n",
    "    StructField(\"col5\", StringType(), True),\\\n",
    "    StructField(\"col6\", StringType(), True),\\\n",
    "    StructField(\"col7\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a80c0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- Temp: string (nullable = true)\n",
      " |-- Value: integer (nullable = true)\n",
      " |-- col4: string (nullable = true)\n",
      " |-- col5: string (nullable = true)\n",
      " |-- col6: string (nullable = true)\n",
      " |-- col7: string (nullable = true)\n",
      "\n",
      "+-----------+--------+----+-----+----+----+----+----+\n",
      "|    station|      id|Temp|Value|col4|col5|col6|col7|\n",
      "+-----------+--------+----+-----+----+----+----+----+\n",
      "|ITE00100554|18000101|TMAX|  -75|null|null|   E|null|\n",
      "|ITE00100554|18000101|TMIN| -148|null|null|   E|null|\n",
      "|GM000010962|18000101|PRCP|    0|null|null|   E|null|\n",
      "|EZE00100082|18000101|TMAX|  -86|null|null|   E|null|\n",
      "|EZE00100082|18000101|TMIN| -135|null|null|   E|null|\n",
      "|ITE00100554|18000102|TMAX|  -60|null|   I|   E|null|\n",
      "|ITE00100554|18000102|TMIN| -125|null|null|   E|null|\n",
      "|GM000010962|18000102|PRCP|    0|null|null|   E|null|\n",
      "|EZE00100082|18000102|TMAX|  -44|null|null|   E|null|\n",
      "|EZE00100082|18000102|TMIN| -130|null|null|   E|null|\n",
      "|ITE00100554|18000103|TMAX|  -23|null|null|   E|null|\n",
      "|ITE00100554|18000103|TMIN|  -46|null|   I|   E|null|\n",
      "|GM000010962|18000103|PRCP|    4|null|null|   E|null|\n",
      "|EZE00100082|18000103|TMAX|  -10|null|null|   E|null|\n",
      "|EZE00100082|18000103|TMIN|  -73|null|null|   E|null|\n",
      "|ITE00100554|18000104|TMAX|    0|null|null|   E|null|\n",
      "|ITE00100554|18000104|TMIN|  -13|null|null|   E|null|\n",
      "|GM000010962|18000104|PRCP|    0|null|null|   E|null|\n",
      "|EZE00100082|18000104|TMAX|  -55|null|null|   E|null|\n",
      "|EZE00100082|18000104|TMIN|  -74|null|null|   E|null|\n",
      "+-----------+--------+----+-----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read.format(\"csv\").option(\"header\",\"false\").schema(schema).load(\"./Exercices_Dataframe/1800.csv\"))\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f15e1e",
   "metadata": {},
   "source": [
    "## Afficher la température minimum et sa station associée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5cf730c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmin = df.filter(df.Temp == \"TMIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "432c70b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|    station|min(Value)|\n",
      "+-----------+----------+\n",
      "|ITE00100554|      -148|\n",
      "|EZE00100082|      -135|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tmin.groupBy(\"station\").min(\"Value\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "87648a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(Value)|\n",
      "+----------+\n",
      "|      -148|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tmin.select([min(\"Value\")]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b18593da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(Value)|\n",
      "+----------+\n",
      "|      -148|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tmin.agg({'Value': 'min'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a4170",
   "metadata": {},
   "source": [
    "# Exercice 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434761e9",
   "metadata": {},
   "source": [
    "## A partir du fichier Lorem_Ipsum.txt. Compter les occurrences de mots à l’aide des méthodes issues des dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db44cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflines=spark.read.text(\"./Exercices_Dataframe/Lorem_Ipsum.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a121d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|What is Lorem Ipsum?|\n",
      "|Lorem Ipsum is si...|\n",
      "|                    |\n",
      "|   Why do we use it?|\n",
      "|It is a long esta...|\n",
      "|                    |\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dflines.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28ef73cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      word|count|\n",
      "+----------+-----+\n",
      "|       the|    9|\n",
      "|        of|    7|\n",
      "|     Lorem|    7|\n",
      "|         a|    7|\n",
      "|       and|    6|\n",
      "|     Ipsum|    5|\n",
      "|        is|    4|\n",
      "|        it|    3|\n",
      "|       has|    3|\n",
      "|        It|    3|\n",
      "|   content|    2|\n",
      "|      that|    2|\n",
      "|  versions|    2|\n",
      "|publishing|    2|\n",
      "|      page|    2|\n",
      "|     their|    2|\n",
      "|      when|    2|\n",
      "|        by|    2|\n",
      "|     dummy|    2|\n",
      "|       use|    2|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfwords=dflines.withColumn('words',split(col('value'),' '))\\\n",
    " .withColumn('word',explode(col('words')))\\\n",
    " .drop('value','words').groupBy('word').agg(count('word')\\\n",
    " .alias('count')).orderBy('count',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ab6d9",
   "metadata": {},
   "source": [
    "## A partir du fichier Book. Compter les occurrences de mots à l’aide des méthodes issues des dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eb501975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|Self-Employment: ...|\n",
      "|Achieving Financi...|\n",
      "|       By Frank Kane|\n",
      "|                    |\n",
      "|                    |\n",
      "|                    |\n",
      "|Copyright � 2015 ...|\n",
      "|All rights reserv...|\n",
      "|                    |\n",
      "|                    |\n",
      "|            CONTENTS|\n",
      "|          Disclaimer|\n",
      "|             Preface|\n",
      "|Part I: Making th...|\n",
      "|  Overcoming Inertia|\n",
      "|     Fear of Failure|\n",
      "|Career Indoctrina...|\n",
      "|The Carrot on a S...|\n",
      "|      Ego Protection|\n",
      "|Your Employer as ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dflines=spark.read.text(\"./Exercices_Dataframe/Book\")\n",
    "dflines.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd564e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               split|\n",
      "+--------------------+\n",
      "|[Self-Employment:...|\n",
      "|[Achieving, Finan...|\n",
      "|   [By, Frank, Kane]|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|[Copyright, �, 20...|\n",
      "|[All, rights, res...|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|          [CONTENTS]|\n",
      "|        [Disclaimer]|\n",
      "|           [Preface]|\n",
      "|[Part, I:, Making...|\n",
      "|[Overcoming, Iner...|\n",
      "| [Fear, of, Failure]|\n",
      "|[Career, Indoctri...|\n",
      "|[The, Carrot, on,...|\n",
      "|   [Ego, Protection]|\n",
      "|[Your, Employer, ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SplitDF = (dflines.select(split(dflines.value, '\\s+').alias('split')))\n",
    "SplitDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc63f939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|            word|\n",
      "+----------------+\n",
      "|Self-Employment:|\n",
      "|        Building|\n",
      "|              an|\n",
      "|        Internet|\n",
      "|        Business|\n",
      "|              of|\n",
      "|             One|\n",
      "|       Achieving|\n",
      "|       Financial|\n",
      "|             and|\n",
      "|        Personal|\n",
      "|         Freedom|\n",
      "|         through|\n",
      "|               a|\n",
      "|       Lifestyle|\n",
      "|      Technology|\n",
      "|        Business|\n",
      "|              By|\n",
      "|           Frank|\n",
      "|            Kane|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SingleDF = (SplitDF.select(explode(SplitDF.split).alias('word')))\n",
    "\n",
    "SingleDFCount = SingleDF.count()\n",
    "\n",
    "SingleDF.show()\n",
    "print(SingleDFCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "29e5f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|         clean|\n",
      "+--------------+\n",
      "|SelfEmployment|\n",
      "|      Building|\n",
      "|            an|\n",
      "|      Internet|\n",
      "|      Business|\n",
      "|            of|\n",
      "|           One|\n",
      "|     Achieving|\n",
      "|     Financial|\n",
      "|           and|\n",
      "|      Personal|\n",
      "|       Freedom|\n",
      "|       through|\n",
      "|             a|\n",
      "|     Lifestyle|\n",
      "|    Technology|\n",
      "|      Business|\n",
      "|            By|\n",
      "|         Frank|\n",
      "|          Kane|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CleanDF = SingleDF.withColumn(\"clean\", regexp_replace(SingleDF['word'], \"[^A-Za-z0-9]\", \"\"))\n",
    "CleanDF = CleanDF.drop('word')\n",
    "CleanDF.show()\n",
    "# add '\\W+ to regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4fe040e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   clean|count|\n",
      "+--------+-----+\n",
      "|      to| 1811|\n",
      "|     you| 1361|\n",
      "|    your| 1339|\n",
      "|     the| 1177|\n",
      "|       a| 1148|\n",
      "|      of|  945|\n",
      "|     and|  904|\n",
      "|    that|  658|\n",
      "|      in|  571|\n",
      "|      is|  542|\n",
      "|     for|  513|\n",
      "|      on|  424|\n",
      "|      it|  412|\n",
      "|     are|  401|\n",
      "|        |  369|\n",
      "|      be|  358|\n",
      "|business|  344|\n",
      "|     can|  330|\n",
      "|       I|  326|\n",
      "|    have|  311|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfwords=CleanDF.groupBy('clean').agg(count('clean')\\\n",
    " .alias('count')).orderBy('count',ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f567f",
   "metadata": {},
   "source": [
    "# Exercice 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c87379",
   "metadata": {},
   "source": [
    "## Calculer la somme des dépenses totales par consommateur à l’aide des méthodes issues des dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "491f9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\\\n",
    "    StructField(\"id\", IntegerType(), True),\\\n",
    "    StructField(\"col2\", IntegerType(), True),\\\n",
    "    StructField(\"depenses\", FloatType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e54de81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------+\n",
      "| id|col2|depenses|\n",
      "+---+----+--------+\n",
      "| 35|5368|   65.89|\n",
      "|  2|3391|   40.64|\n",
      "| 47|6694|   14.98|\n",
      "| 29| 680|   13.08|\n",
      "| 91|8900|   24.59|\n",
      "| 70|3959|   68.68|\n",
      "| 85|1733|   28.53|\n",
      "| 53|9900|   83.55|\n",
      "| 14|1505|    4.32|\n",
      "| 51|3378|    19.8|\n",
      "| 42|6926|   57.77|\n",
      "|  2|4424|   55.77|\n",
      "| 79|9291|   33.17|\n",
      "| 50|3901|   23.57|\n",
      "| 20|6633|    6.49|\n",
      "| 15|6148|   65.53|\n",
      "| 44|8331|   99.19|\n",
      "|  5|3505|   64.18|\n",
      "| 48|5539|   32.42|\n",
      "| 47|9900|   25.66|\n",
      "+---+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read.format(\"csv\").option(\"header\",\"true\").schema(schema).load(\"./Exercices_Dataframe/customer-orders.csv\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "640df505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|     sum(depenses)|\n",
      "+---+------------------+\n",
      "|  0| 5524.950008839369|\n",
      "|  1| 4958.599974133074|\n",
      "|  2| 5994.589979887009|\n",
      "|  3| 4659.629958629608|\n",
      "|  4| 4815.050017774105|\n",
      "|  5|4561.0700044333935|\n",
      "|  6| 5397.880012750626|\n",
      "|  7| 4755.070008277893|\n",
      "|  8|5517.2399980425835|\n",
      "|  9|  5322.64999294281|\n",
      "| 10| 4819.699996152893|\n",
      "| 11| 5152.289969373494|\n",
      "| 12| 4664.589988231659|\n",
      "| 13| 4367.619992315769|\n",
      "| 14|4735.0300142765045|\n",
      "| 15| 5413.510010659695|\n",
      "| 16| 4979.059988319874|\n",
      "| 17| 5032.680001735687|\n",
      "| 18|4921.2700062170625|\n",
      "| 19| 5059.429994106293|\n",
      "+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"id\").sum(\"depenses\").orderBy('id',ascending=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aca1cc",
   "metadata": {},
   "source": [
    "# Exercice 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14c9af",
   "metadata": {},
   "source": [
    "## Classer les films par degré de popularité (Du plus populaire au moins populaire. Afficher les 10 premiers films les plus populaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "056cb30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|196\\t242\\t3\\t8812...|\n",
      "|186\\t302\\t3\\t8917...|\n",
      "|22\\t377\\t1\\t87888...|\n",
      "|244\\t51\\t2\\t88060...|\n",
      "|166\\t346\\t1\\t8863...|\n",
      "|298\\t474\\t4\\t8841...|\n",
      "|115\\t265\\t2\\t8811...|\n",
      "|253\\t465\\t5\\t8916...|\n",
      "|305\\t451\\t3\\t8863...|\n",
      "| 6\\t86\\t3\\t883603013|\n",
      "|62\\t257\\t2\\t87937...|\n",
      "|286\\t1014\\t5\\t879...|\n",
      "|200\\t222\\t5\\t8760...|\n",
      "|210\\t40\\t3\\t89103...|\n",
      "|224\\t29\\t3\\t88810...|\n",
      "|303\\t785\\t3\\t8794...|\n",
      "|122\\t387\\t5\\t8792...|\n",
      "|194\\t274\\t2\\t8795...|\n",
      "|291\\t1042\\t4\\t874...|\n",
      "|234\\t1184\\t2\\t892...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfdata=spark.read.(\"./Exercices_Dataframe/u.data\")\n",
    "dfdata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b140018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\\\n",
    "    StructField(\"id_film\", IntegerType(), True),\\\n",
    "    StructField(\"id_util\", IntegerType(), True),\\\n",
    "    StructField(\"note\", IntegerType(), True),\\\n",
    "    StructField(\"timestamp\", IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8a42fcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+---------+\n",
      "|id_film|id_util|note|timestamp|\n",
      "+-------+-------+----+---------+\n",
      "|    196|    242|   3|881250949|\n",
      "|    186|    302|   3|891717742|\n",
      "|     22|    377|   1|878887116|\n",
      "|    244|     51|   2|880606923|\n",
      "|    166|    346|   1|886397596|\n",
      "|    298|    474|   4|884182806|\n",
      "|    115|    265|   2|881171488|\n",
      "|    253|    465|   5|891628467|\n",
      "|    305|    451|   3|886324817|\n",
      "|      6|     86|   3|883603013|\n",
      "|     62|    257|   2|879372434|\n",
      "|    286|   1014|   5|879781125|\n",
      "|    200|    222|   5|876042340|\n",
      "|    210|     40|   3|891035994|\n",
      "|    224|     29|   3|888104457|\n",
      "|    303|    785|   3|879485318|\n",
      "|    122|    387|   5|879270459|\n",
      "|    194|    274|   2|879539794|\n",
      "|    291|   1042|   4|874834944|\n",
      "|    234|   1184|   2|892079237|\n",
      "+-------+-------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read.format(\"csv\").option(\"header\",\"false\").option(\"sep\",\"\\t\").schema(schema).load(\"./Exercices_Dataframe/u.data\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b678e681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|id_film|        avg(note)|\n",
      "+-------+-----------------+\n",
      "|    849|4.869565217391305|\n",
      "|    688|4.833333333333333|\n",
      "|    507|4.724137931034483|\n",
      "|    628|4.703703703703703|\n",
      "|    928|           4.6875|\n",
      "|    118|4.661971830985915|\n",
      "|    907|4.571428571428571|\n",
      "|    686|4.563380281690141|\n",
      "|    427|4.548387096774194|\n",
      "|    565|4.542857142857143|\n",
      "+-------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"id_film\").mean(\"note\").orderBy(\"avg(note)\",ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a0ea58f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|id_film|        avg(note)|\n",
      "+-------+-----------------+\n",
      "|    849|4.869565217391305|\n",
      "|    688|4.833333333333333|\n",
      "|    507|4.724137931034483|\n",
      "|    628|4.703703703703703|\n",
      "|    928|           4.6875|\n",
      "|    118|4.661971830985915|\n",
      "|    907|4.571428571428571|\n",
      "|    686|4.563380281690141|\n",
      "|    427|4.548387096774194|\n",
      "|    565|4.542857142857143|\n",
      "+-------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"id_film\").agg({\"note\":\"avg\"}).orderBy(\"avg(note)\",ascending=False).show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
