{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e775f6b6",
   "metadata": {},
   "source": [
    "# Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d70f16b",
   "metadata": {},
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebff267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrameReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d500265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation de findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ccf0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création du SparkSession\n",
    "spark = SparkSession.builder.appName(\"Exemple Spark\").getOrCreate()\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799f4827",
   "metadata": {},
   "source": [
    "## Importer le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf866152",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\\\n",
    "    StructField(\"id_film\", IntegerType(), True),\\\n",
    "    StructField(\"id_util\", IntegerType(), True),\\\n",
    "    StructField(\"note\", IntegerType(), True),\\\n",
    "    StructField(\"timestamp\", IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9686e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+---------+\n",
      "|id_film|id_util|note|timestamp|\n",
      "+-------+-------+----+---------+\n",
      "|    196|    242|   3|881250949|\n",
      "|    186|    302|   3|891717742|\n",
      "|     22|    377|   1|878887116|\n",
      "|    244|     51|   2|880606923|\n",
      "|    166|    346|   1|886397596|\n",
      "|    298|    474|   4|884182806|\n",
      "|    115|    265|   2|881171488|\n",
      "|    253|    465|   5|891628467|\n",
      "|    305|    451|   3|886324817|\n",
      "|      6|     86|   3|883603013|\n",
      "|     62|    257|   2|879372434|\n",
      "|    286|   1014|   5|879781125|\n",
      "|    200|    222|   5|876042340|\n",
      "|    210|     40|   3|891035994|\n",
      "|    224|     29|   3|888104457|\n",
      "|    303|    785|   3|879485318|\n",
      "|    122|    387|   5|879270459|\n",
      "|    194|    274|   2|879539794|\n",
      "|    291|   1042|   4|874834944|\n",
      "|    234|   1184|   2|892079237|\n",
      "+-------+-------+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_ratings = (spark.read.format(\"csv\").option(\"header\",\"false\").option(\"sep\",\"\\t\").schema(schema).load(\"./Exercices_Dataframe/u.data\"))\n",
    "movies_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e42628",
   "metadata": {},
   "source": [
    "## Split des données 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d258f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train set\n",
    "(train, test) = movies_ratings.randomSplit([0.8, 0.2], seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad58acb",
   "metadata": {},
   "source": [
    "## Création du modèle et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b3a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required functions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(\n",
    "         itemCol=\"id_film\",\n",
    "         userCol=\"id_util\", \n",
    "         ratingCol=\"note\", \n",
    "         nonnegative = True, \n",
    "         implicitPrefs = False,\n",
    "         coldStartStrategy=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4922e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"note\", predictionCol=\"prediction\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc1bead",
   "metadata": {},
   "source": [
    "## Prédictions et score du Modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49cd2bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+---------+----------+\n",
      "|id_film|id_util|note|timestamp|prediction|\n",
      "+-------+-------+----+---------+----------+\n",
      "|      6|    463|   4|883601713| 3.3823757|\n",
      "|      7|    463|   4|891353192| 3.6681702|\n",
      "|      7|    496|   5|891351083| 4.5561175|\n",
      "|     10|    496|   5|877889005| 4.4123445|\n",
      "|     13|    471|   1|882140455|  3.126554|\n",
      "|     16|    471|   3|877724845| 4.0041533|\n",
      "|     21|    148|   1|874951482| 2.4498372|\n",
      "|     42|    496|   5|881107718|  4.707486|\n",
      "|     65|    471|   4|879217434| 3.5055668|\n",
      "|     67|    833|   4|875379794| 3.2711296|\n",
      "|     75|    833|   2|884051113| 3.2874758|\n",
      "|     83|    471|   3|891182000| 3.7135022|\n",
      "|     84|    148|   4|883452274| 3.5118935|\n",
      "|     92|    148|   2|877383934| 2.8538518|\n",
      "|     92|    463|   4|875656623| 3.8172255|\n",
      "|     94|    496|   3|885873159|  4.060447|\n",
      "|     95|    471|   5|884266051|   3.58706|\n",
      "|     95|    496|   4|879198746|  4.300857|\n",
      "|     99|    471|   4|885679091| 3.5642917|\n",
      "|    119|    471|   4|886177338|   3.81331|\n",
      "+-------+-------+----+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "0.919026040899729\n"
     ]
    }
   ],
   "source": [
    "#Fit model to the 'train' dataset\n",
    "model = als.fit(train)\n",
    "\n",
    "# View the predictions\n",
    "test_predictions = model.transform(test)\n",
    "test_predictions.show()\n",
    "\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4466a430",
   "metadata": {},
   "source": [
    "## Recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a0cc368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|id_util|     recommendations|\n",
      "+-------+--------------------+\n",
      "|      1|[{688, 5.5186486}...|\n",
      "|     12|[{688, 5.311125},...|\n",
      "|     22|[{688, 5.770404},...|\n",
      "|     26|[{688, 4.84113}, ...|\n",
      "|     27|[{519, 4.728087},...|\n",
      "|     28|[{688, 5.523353},...|\n",
      "|     31|[{688, 4.940987},...|\n",
      "|     34|[{628, 4.419863},...|\n",
      "|     44|[{688, 4.4623766}...|\n",
      "|     47|[{688, 4.7291183}...|\n",
      "|     52|[{519, 4.594738},...|\n",
      "|     53|[{366, 4.670725},...|\n",
      "|     65|[{300, 4.927075},...|\n",
      "|     76|[{688, 4.8965645}...|\n",
      "|     78|[{688, 4.5673275}...|\n",
      "|     81|[{118, 4.411306},...|\n",
      "|     85|[{546, 4.3037753}...|\n",
      "|     91|[{928, 5.133658},...|\n",
      "|     93|[{4, 4.8318295}, ...|\n",
      "|    101|[{636, 4.9133534}...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec = model.recommendForAllUsers(5)\n",
    "rec.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f294008a",
   "metadata": {},
   "source": [
    "# Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57adcef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+--------+-------------+-----------------------+--------+---------+---------------+\n",
      "| No|TransactionDate|HouseAge|DistanceToMRT|NumberConvenienceStores|Latitude|Longitude|PriceOfUnitArea|\n",
      "+---+---------------+--------+-------------+-----------------------+--------+---------+---------------+\n",
      "|  1|       2012.917|      32|     84.87882|                     10|24.98298|121.54024|           37.9|\n",
      "|  2|       2012.917|    19.5|     306.5947|                      9|24.98034|121.53951|           42.2|\n",
      "|  3|       2013.583|    13.3|     561.9845|                      5|24.98746|121.54391|           47.3|\n",
      "|  4|         2013.5|    13.3|     561.9845|                      5|24.98746|121.54391|           54.8|\n",
      "|  5|       2012.833|       5|     390.5684|                      5|24.97937|121.54245|           43.1|\n",
      "|  6|       2012.667|     7.1|      2175.03|                      3|24.96305|121.51254|           32.1|\n",
      "|  7|       2012.667|    34.5|     623.4731|                      7|24.97933|121.53642|           40.3|\n",
      "|  8|       2013.417|    20.3|     287.6025|                      6|24.98042|121.54228|           46.7|\n",
      "|  9|         2013.5|    31.7|     5512.038|                      1|24.95095|121.48458|           18.8|\n",
      "| 10|       2013.417|    17.9|      1783.18|                      3|24.96731|121.51486|           22.1|\n",
      "| 11|       2013.083|    34.8|     405.2134|                      1|24.97349|121.53372|           41.4|\n",
      "| 12|       2013.333|     6.3|     90.45606|                      9|24.97433| 121.5431|           58.1|\n",
      "| 13|       2012.917|      13|     492.2313|                      5|24.96515|121.53737|           39.3|\n",
      "| 14|       2012.667|    20.4|     2469.645|                      4|24.96108|121.51046|           23.8|\n",
      "| 15|         2013.5|    13.2|     1164.838|                      4|24.99156|121.53406|           34.3|\n",
      "| 16|       2013.583|    35.7|     579.2083|                      2| 24.9824|121.54619|           50.5|\n",
      "| 17|        2013.25|       0|     292.9978|                      6|24.97744|121.54458|           70.1|\n",
      "| 18|        2012.75|    17.7|     350.8515|                      1|24.97544|121.53119|           37.4|\n",
      "| 19|       2013.417|    16.9|     368.1363|                      8| 24.9675|121.54451|           42.3|\n",
      "| 20|       2012.667|     1.5|     23.38284|                      7|24.96772|121.54102|           47.7|\n",
      "+---+---------------+--------+-------------+-----------------------+--------+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (spark.read.format(\"csv\").option(\"header\",\"true\").load(\"./Exercices_SparkML/realestate.csv\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e0f2fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: integer (nullable = true)\n",
      " |-- TransactionDate: float (nullable = true)\n",
      " |-- HouseAge: float (nullable = true)\n",
      " |-- DistanceToMRT: float (nullable = true)\n",
      " |-- NumberConvenienceStores: integer (nullable = true)\n",
      " |-- Latitude: float (nullable = true)\n",
      " |-- Longitude: float (nullable = true)\n",
      " |-- PriceOfUnitArea: float (nullable = true)\n",
      "\n",
      "+---+---------------+--------+-------------+-----------------------+--------+---------+---------------+\n",
      "| No|TransactionDate|HouseAge|DistanceToMRT|NumberConvenienceStores|Latitude|Longitude|PriceOfUnitArea|\n",
      "+---+---------------+--------+-------------+-----------------------+--------+---------+---------------+\n",
      "|  1|       2012.917|    32.0|     84.87882|                     10|24.98298|121.54024|           37.9|\n",
      "|  2|       2012.917|    19.5|     306.5947|                      9|24.98034|121.53951|           42.2|\n",
      "|  3|       2013.583|    13.3|     561.9845|                      5|24.98746|121.54391|           47.3|\n",
      "|  4|         2013.5|    13.3|     561.9845|                      5|24.98746|121.54391|           54.8|\n",
      "|  5|       2012.833|     5.0|     390.5684|                      5|24.97937|121.54245|           43.1|\n",
      "|  6|       2012.667|     7.1|      2175.03|                      3|24.96305|121.51254|           32.1|\n",
      "|  7|       2012.667|    34.5|     623.4731|                      7|24.97933|121.53642|           40.3|\n",
      "|  8|       2013.417|    20.3|     287.6025|                      6|24.98042|121.54228|           46.7|\n",
      "|  9|         2013.5|    31.7|     5512.038|                      1|24.95095|121.48458|           18.8|\n",
      "| 10|       2013.417|    17.9|      1783.18|                      3|24.96731|121.51486|           22.1|\n",
      "| 11|       2013.083|    34.8|     405.2134|                      1|24.97349|121.53372|           41.4|\n",
      "| 12|       2013.333|     6.3|     90.45606|                      9|24.97433| 121.5431|           58.1|\n",
      "| 13|       2012.917|    13.0|     492.2313|                      5|24.96515|121.53737|           39.3|\n",
      "| 14|       2012.667|    20.4|     2469.645|                      4|24.96108|121.51046|           23.8|\n",
      "| 15|         2013.5|    13.2|     1164.838|                      4|24.99156|121.53406|           34.3|\n",
      "| 16|       2013.583|    35.7|     579.2083|                      2| 24.9824|121.54619|           50.5|\n",
      "| 17|        2013.25|     0.0|     292.9978|                      6|24.97744|121.54458|           70.1|\n",
      "| 18|        2012.75|    17.7|     350.8515|                      1|24.97544|121.53119|           37.4|\n",
      "| 19|       2013.417|    16.9|     368.1363|                      8| 24.9675|121.54451|           42.3|\n",
      "| 20|       2012.667|     1.5|     23.38284|                      7|24.96772|121.54102|           47.7|\n",
      "+---+---------------+--------+-------------+-----------------------+--------+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.selectExpr(\"cast(No as int) No\",\n",
    "    \"cast(TransactionDate as float) TransactionDate\",\n",
    "    \"cast(HouseAge as float) HouseAge\",\n",
    "    \"cast(DistanceToMRT as float) DistanceToMRT\",\n",
    "    \"cast(NumberConvenienceStores as int) NumberConvenienceStores\",\n",
    "    \"cast(Latitude as float) Latitude\", \n",
    "    \"cast(Longitude as float) Longitude\",\n",
    "    \"cast(PriceOfUnitArea as float) PriceOfUnitArea\")               \n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfcce9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  ['No', 'TransactionDate', 'HouseAge', 'DistanceToMRT', 'NumberConvenienceStores', 'Latitude']\n",
      "label:  PriceOfUnitArea\n"
     ]
    }
   ],
   "source": [
    "features = df.columns[0:6]\n",
    "label = df.columns[-1]\n",
    "print(\"features: \", features)\n",
    "print(\"label: \", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "226df634",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Data type string of column No is not supported.\nData type string of column TransactionDate is not supported.\nData type string of column HouseAge is not supported.\nData type string of column DistanceToMRT is not supported.\nData type string of column NumberConvenienceStores is not supported.\nData type string of column Latitude is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorAssembler\n\u001b[0;32m      2\u001b[0m assembler \u001b[38;5;241m=\u001b[39m VectorAssembler(inputCols \u001b[38;5;241m=\u001b[39m features, outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43massembler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m output\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclicked\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow(truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\ml\\base.py:217\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\ml\\wrapper.py:350\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m, dataset\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py:1309\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1303\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1305\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1306\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1308\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1309\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1313\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: Data type string of column No is not supported.\nData type string of column TransactionDate is not supported.\nData type string of column HouseAge is not supported.\nData type string of column DistanceToMRT is not supported.\nData type string of column NumberConvenienceStores is not supported.\nData type string of column Latitude is not supported."
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols = features, outputCol=\"features\")\n",
    "output = assembler.transform(df)\n",
    "output.select(\"features\", \"clicked\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = output.randomSplit([0.8, 0.2], seed = 42)\n",
    "print(train.count())\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea062bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decison_Tree = DecisionTreeRegressor(featuresCol = \"features\", labelCol = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=label, predictionCol=\"prediction\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model to the 'train' dataset\n",
    "model = Decison_Tree.fit(train)\n",
    "\n",
    "# View the predictions\n",
    "test_predictions = model.transform(test)\n",
    "test_predictions.show()\n",
    "\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
